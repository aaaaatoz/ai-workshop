# Digital User Engagement Events Database Solution
#
# template for digital-user-engagement-events-database
# **DO NOT DELETE**
#
# author: rjlowe@
AWSTemplateFormatVersion: 2010-09-09

Description: (SO0105) - Automatically provision and configure the AWS services necessary to start analyzing real-time data from Amazon Simple Email Service and Amazon Pinpoint using Amazon Athena.(SO0079) - Predictive Segmentation using Amazon Pinpoint and Amazon SageMaker solution - Daily update of an Amazon Pinpoint segment with users identified by Amazon SageMaker machine learning models.

Parameters:

  PinpointProjectName:
    Type: String
    Default: "EdTech"
    Description: "Name to be used to create the Pinpoint project"
  ConfigurationSetNames:
    Type: String
    Description: If already configured, Comma delimitated list of existing SES configuration sets to update with a Pinpoint event destination.  Ensure no Pinpoint Event Destination is already configured.
    Default: ""
  EventAthenaDatabaseName:
    Type: String
    Description: Name of the Athena database created in Glue, must be lowercase
    Default: "due_eventdb"
    AllowedPattern: ^[a-z][a-z0-9_]*$
    ConstraintDescription: Only lower case and the underscore (_) characters are allowed

  SageMakerModelTrainInstanceType:
    Type: String
    Default: ml.m4.xlarge
    Description: GPU Instance type for model training job.
  SageMakerTransformInstanceType:
    Type: String
    Default: ml.m5.large
    Description: GPU Instance type for daily bulk transform jobs.
  DeploySampleEvents:
    Type: String
    Description: Indicate whether sample/fictitious event data should be loaded into the Digital User Engagement Events Database S3 bucket for demonstration purposes.
    AllowedValues:
      - 'Yes'
      - 'No'
    Default: "Yes"
  # VPCId:
  #   Type: AWS::EC2::VPC::Id
  #   Description: "Select the VPC to deploy the SageMaker notebook instance."
  # VPCPubSub:
  #   Type: AWS::EC2::Subnet::Id
  #   Description: "Select the Subnet Id for the notebook instance."    

Mappings:
  MetricsMap:
    Send-Data:
      ID: SO0105
      Version: "v1.0.0"
      SendAnonymousData: "Yes" # change to 'No' if needed

  SourceCode:
    General:
      S3Bucket: "solutions"
      KeyPrefix: "digital-user-engagement-events-database/v1.0.0"

  LambdaRuntime:
    Language:
      Python: python3.7

  SourceCodePS:
    General:
      S3Bucket: "solutions"
      KeyPrefix: "predictive-segmentation-using-amazon-pinpoint-and-amazon-sagemaker/v1.1.0"
    Runtime:
      Nodejs: "nodejs12.x"
  Variables:
    General:
      MetricName: "ChurnPrediction"
      SegmentName: "Predicted to Churn"
      ChurnPredictionThreashold: "0.40"
      SageMakerModelName: "deployed-xgboost-customer-churn"      

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: Amazon Pinpoint Project Configuration
        Parameters:
          - PinpointProjectName
      -
        Label:
          default: Amazon Simple Email Service Configuration
        Parameters:
          - ConfigurationSetNames
      -
        Label:
          default: Amazon Athena Data Lake Configuration
        Parameters:
          - EventAthenaDatabaseName
      -
        Label:
          default: Digital User Engagement Events Database Solution Configuration
        Parameters:
          - DeploySampleEvents
      -
        Label:
          default: SageMaker Training and Notebook Configuration
        Parameters:
          - SageMakerModelTrainInstanceType
          - SageMakerTransformInstanceType
          # - VPCId
          # - VPCPubSub


    ParameterLabels:
      PinpointProjectName:
        default: Amazon Pinpoint Project Name
      ConfigurationSetNames:
        default: Existing Amazon Simple Email Service Configuration Set Names
      EventAthenaDatabaseName:
        default: Amazon Athena / AWS Glue Database Name
      DeploySampleEvents:
        default: Load Sample Events
      SageMakerModelTrainInstanceType:
        default: Model Training Instance Type
      SageMakerTransformInstanceType:
        default: Transformation Instance Type
      # VPCId:
      #   default: VPC Id
      # VPCPubSub:
      #   default: Subnet Id


Conditions:
  LoadSampleEvents: !Equals ['Yes', !Ref DeploySampleEvents]

Resources:
  PinpointProject:
    Type: AWS::Pinpoint::App
    # DeletionPolicy: Retain
    Properties:
      Name: !Ref PinpointProjectName


  ##### S3 BUCKETS
  #######################################

  DUES3DataLake:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W51
            reason: Not public facing.
    Properties:
      BucketName: !Ref DUES3DataLakeName
      PublicAccessBlockConfiguration:
        BlockPublicAcls: True
        BlockPublicPolicy: True
        IgnorePublicAcls: True
        RestrictPublicBuckets: True
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      LoggingConfiguration:
        DestinationBucketName: !Ref LogBucket
        LogFilePrefix: pinpoint-event-processing/
      NotificationConfiguration:
        LambdaConfigurations:
          -
            Event: "s3:ObjectCreated:*"
            Filter:
              S3Key:
                Rules:
                  - Name: "prefix"
                    Value: "events/"
            Function: !GetAtt AthenaPartitionLambda.Arn

  DUES3DataLakePolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref DUES3DataLake
      PolicyDocument:
        Version: 2012-10-17
        Statement:
        - Sid: AllowSSLRequestsOnly
          Effect: Deny
          Principal: "*"
          Action: "s3:*"
          Resource:
            - !Sub "arn:aws:s3:::${DUES3DataLakeName}/*"
            - !Sub "arn:aws:s3:::${DUES3DataLakeName}"
          Condition:
            Bool:
              "aws:SecureTransport": "false"

  S3InvokeLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref AthenaPartitionLambda
      Principal: s3.amazonaws.com
      SourceArn: !Sub arn:aws:s3:::${DUES3DataLakeName}
      SourceAccount: !Ref "AWS::AccountId"

  LogBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W35
            reason: This is the log bucket.
    Properties:
      AccessControl: LogDeliveryWrite
      PublicAccessBlockConfiguration:
        BlockPublicAcls: True
        BlockPublicPolicy: True
        IgnorePublicAcls: True
        RestrictPublicBuckets: True
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256

  LogBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref LogBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
        - Sid: AWSCloudTrailAclCheck
          Effect: Allow
          Principal:
            Service: cloudtrail.amazonaws.com
          Action: "s3:GetBucketAcl"
          Resource: !Sub arn:aws:s3:::${LogBucket}
        - Sid: AWSCloudTrailWrite
          Effect: Allow
          Principal:
            Service: cloudtrail.amazonaws.com
          Action: "s3:PutObject"
          Resource: !Sub arn:aws:s3:::${LogBucket}/AWSLogs/${AWS::AccountId}/*
          Condition:
            StringEquals:
              "s3:x-amz-acl": "bucket-owner-full-control"
        - Sid: LogBucketAllowSSLRequestsOnly
          Effect: Deny
          Principal: "*"
          Action: "s3:*"
          Resource:
            - !Sub "arn:aws:s3:::${LogBucket}/*"
            - !Sub "arn:aws:s3:::${LogBucket}"
          Condition:
            Bool:
              "aws:SecureTransport": "false"


  #### KINESIS FIREHOSE - Pinpoint
  #######################################
  PinpointEventStream:
    Type: AWS::Pinpoint::EventStream
    Properties:
      ApplicationId: !Ref PinpointProject
      DestinationStreamArn: !GetAtt PinpointEventFirehose.Arn
      RoleArn: !GetAtt PinpointKinesisStreamRole.Arn

  PinpointEventFirehose:
    Type: AWS::KinesisFirehose::DeliveryStream
    DependsOn: 
      - SetupSampleFilesDUE
    Properties:
      DeliveryStreamType: "DirectPut"
      ExtendedS3DestinationConfiguration:
        BucketARN: !Sub "arn:aws:s3:::${DUES3DataLake}"
        BufferingHints:
          IntervalInSeconds: 300
          SizeInMBs: 128
        DataFormatConversionConfiguration:
          Enabled: true
          InputFormatConfiguration:
            Deserializer:
              OpenXJsonSerDe: {}
          OutputFormatConfiguration:
            Serializer:
              ParquetSerDe: {}
          SchemaConfiguration:
            DatabaseName: !Ref PinpointEventDatabase
            Region: !Ref AWS::Region
            RoleARN: !GetAtt PinpointKinesisFirehoseRole.Arn
            TableName: "all_events"
            VersionId: "LATEST"
            CatalogId: !Ref AWS::AccountId
        CompressionFormat: "UNCOMPRESSED"
        Prefix: "events/"
        ErrorOutputPrefix: "errors/"
        RoleARN: !GetAtt PinpointKinesisFirehoseRole.Arn
        CloudWatchLoggingOptions:
          Enabled: true
          LogGroupName: !Sub "/aws/kinesisfirehose/${AWS::StackName}-pinpoint-eventstream-firehose"
          LogStreamName: "S3DeliveryErrors"

  KinesisFirehoseLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "/aws/kinesisfirehose/${AWS::StackName}-pinpoint-eventstream-firehose"

  KinesisFirehoseLogStreamName:
    Type: AWS::Logs::LogStream
    DependsOn: KinesisFirehoseLogGroup
    Properties:
      LogGroupName: !Sub "/aws/kinesisfirehose/${AWS::StackName}-pinpoint-eventstream-firehose"
      LogStreamName: "S3DeliveryErrors"

  PinpointKinesisStreamRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - pinpoint.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "firehose:PutRecordBatch"
                  - "firehose:DescribeDeliveryStream"
                Resource: !GetAtt PinpointEventFirehose.Arn

  PinpointKinesisFirehoseRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - firehose.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "s3:AbortMultipartUpload"
                  - "s3:GetBucketLocation"
                  - "s3:GetObject"
                  - "s3:ListBucket"
                  - "s3:ListBucketMultipartUploads"
                  - "s3:PutObject"
                Resource:
                  - !Sub "arn:aws:s3:::${DUES3DataLakeName}/*"
                  - !Sub "arn:aws:s3:::${DUES3DataLakeName}"
              -
                Effect: "Allow"
                Action:
                  - "glue:GetTable"
                  - "glue:GetTableVersion"
                  - "glue:GetTableVersions"
                Resource:
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${EventAthenaDatabaseName}/*"
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${EventAthenaDatabaseName}"
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog"
              -
                Effect: "Allow"
                Action: "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/kinesisfirehose/*:log-stream:*"
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"


  #### GLUE AND ATHENA
  #######################################
  PinpointEventDatabase:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Ref EventAthenaDatabaseName
        Description: "SES and Pinpoint Streaming Event Database"

  EventTableAllNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref EventAthenaDatabaseName
      Description: "Create a Table for All events"
      QueryString:
        !Sub
          |
            CREATE EXTERNAL TABLE IF NOT EXISTS `all_events` (
              event_type string,
              event_timestamp bigint,
              arrival_timestamp bigint,
              event_version string,
              application struct<app_id:string,sdk:map<string,string>>,
              client struct<client_id:string,cognito_id:string>,
              device struct<platform:map<string,string>>,
              session map<string,string>,
              attributes map<string,string>,
              client_context struct<custom:map<string,string>>,
              awsAccountId string,
              facets struct<
                email_channel:struct<
                  mail_event:struct<
                    mail:struct<
                      message_id:string,
                      message_send_timestamp:bigint,
                      from_address:string,
                      destination:array<string>,
                      headers_truncated:boolean,
                      headers:array<map<string,string>>,
                      common_headers:struct<
                        `from`:string,
                        to:array<string>,
                        subject:string
                      >
                    >,
                    send:map<string,string>,
                    delivery:struct<
                      smtp_response:string,
                      reporting_mta:string,
                      recipients:array<string>,
                      processing_time_millis:int
                    >,
                    `open`:struct<
                      `ip_address`:string,
                      `user_agent`:string
                    >,
                    `click`:struct<
                      `ip_address`:string,
                      `user_agent`:string,
                      `link`:string,
                      `link_tags`:struct<
                        `unsubscribeLinkTag`:array<string>
                      >
                    >,
                    reject:struct<
                      reason:string
                    >,
                    complaint:struct<
                      complained_recipients:array<struct<email_address:string>>,
                      feedback_id:string,
                      user_agent:string,
                      complaint_feedback_type:string
                    >,
                    `bounce`:struct<
                      bounce_type:string,
                      bounce_sub_type:string,
                      bounced_recipients:array<struct<email_address:string,`action`:string,`status`:string,diagnostic_code:string>>,
                      feedback_id:string,
                      reporting_mta:string
                    >
                  >
                >
              >,
              metrics struct<price_in_millicents_usd:double>
            )
            PARTITIONED BY (ingest_timestamp timestamp)
            STORED AS parquet
            LOCATION 's3://${DUES3DataLakeName}/events'
            TBLPROPERTIES ("parquet.compression"="SNAPPY")

  EventTableSendNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Send View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_send AS
            SELECT
                from_unixtime((event_timestamp / 1000)) event_timestamp
              , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
              , application.app_id application_id
              , client.client_id endpoint_id
              , attributes['campaign_id'] pinpoint_campaign_id
              , attributes['treament_id'] pinpoint_treatment_id
              , awsaccountid aws_account_id
              , facets.email_channel.mail_event.mail.message_id message_id
              , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
              , facets.email_channel.mail_event.mail.from_address from_address
              , facets.email_channel.mail_event.mail.destination destination
              , facets.email_channel.mail_event.mail.common_headers.subject as subject
              , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
              , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_email.send')


  EventTableHardBounceNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Hard Bounce View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_hardbounce AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , facets.email_channel.mail_event.mail.message_id message_id
            , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
            , facets.email_channel.mail_event.mail.from_address from_address
            , facets.email_channel.mail_event.mail.destination destination
            , facets.email_channel.mail_event.bounce.bounce_type as bounce_type
            , facets.email_channel.mail_event.bounce.bounce_sub_type as bounce_sub_type
            , facets.email_channel.mail_event.bounce.feedback_id as feedback_id
            , facets.email_channel.mail_event.bounce.reporting_mta as reporting_mta
            , bounced_recipient.email_address as bounced_recipient_email_address
            , bounced_recipient.action as bounced_recipient_action
            , bounced_recipient.status as bounced_recipient_status
            , bounced_recipient.diagnostic_code as bounced_recipient_diagnostic_code
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
              CROSS JOIN UNNEST(facets.email_channel.mail_event.bounce.bounced_recipients) as t(bounced_recipient)
            WHERE (event_type = '_email.hardbounce')

  EventTableSoftBounceNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Soft Bounce View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_softbounce AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , facets.email_channel.mail_event.mail.message_id message_id
            , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
            , facets.email_channel.mail_event.mail.from_address from_address
            , facets.email_channel.mail_event.mail.destination destination
            , facets.email_channel.mail_event.bounce.bounce_type as bounce_type
            , facets.email_channel.mail_event.bounce.bounce_sub_type as bounce_sub_type
            , facets.email_channel.mail_event.bounce.feedback_id as feedback_id
            , facets.email_channel.mail_event.bounce.reporting_mta as reporting_mta
            , bounced_recipient.email_address as bounced_recipient_email_address
            , bounced_recipient.action as bounced_recipient_action
            , bounced_recipient.status as bounced_recipient_status
            , bounced_recipient.diagnostic_code as bounced_recipient_diagnostic_code
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
              CROSS JOIN UNNEST(facets.email_channel.mail_event.bounce.bounced_recipients) as t(bounced_recipient)
            WHERE (event_type = '_email.softbounce')

  EventTableComplaintNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Complaint View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_complaint AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , facets.email_channel.mail_event.mail.message_id message_id
            , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
            , facets.email_channel.mail_event.mail.from_address from_address
            , facets.email_channel.mail_event.mail.destination destination
            , complained_recipient.email_address as complained_email_address
            , facets.email_channel.mail_event.complaint.feedback_id as feedback_id
            , facets.email_channel.mail_event.complaint.user_agent as user_agent
            , facets.email_channel.mail_event.complaint.complaint_feedback_type as complaint_feedback_type
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
              CROSS JOIN UNNEST(facets.email_channel.mail_event.complaint.complained_recipients) as t(complained_recipient)
            WHERE (event_type = '_email.complaint')

  EventTableDeliveryNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Delivered View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_delivered AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , facets.email_channel.mail_event.mail.message_id message_id
            , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
            , facets.email_channel.mail_event.mail.from_address from_address
            , facets.email_channel.mail_event.mail.destination destination
            , facets.email_channel.mail_event.mail.common_headers.subject as subject
            , facets.email_channel.mail_event.delivery.smtp_response as smtp_response
            , facets.email_channel.mail_event.delivery.reporting_mta as reporting_mta
            , facets.email_channel.mail_event.delivery.recipients as recipients
            , facets.email_channel.mail_event.delivery.processing_time_millis as processing_time_millis
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_email.delivered')

  EventTableOpenNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Open View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_open AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , facets.email_channel.mail_event.mail.message_id message_id
            , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
            , facets.email_channel.mail_event.mail.from_address from_address
            , facets.email_channel.mail_event.mail.destination destination
            , facets.email_channel.mail_event.mail.common_headers.subject as subject
            , facets.email_channel.mail_event.open.ip_address as ip_address
            , facets.email_channel.mail_event.open.user_agent as user_agent
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_email.open')

  EventTableClickNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Click View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_click AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , facets.email_channel.mail_event.mail.message_id message_id
            , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
            , facets.email_channel.mail_event.mail.from_address from_address
            , facets.email_channel.mail_event.mail.destination destination
            , facets.email_channel.mail_event.mail.common_headers.subject as subject
            , facets.email_channel.mail_event.click.ip_address as ip_address
            , facets.email_channel.mail_event.click.user_agent as user_agent
            , facets.email_channel.mail_event.click.link as link
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_email.click')

  EventTableUnsubNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Unsub View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_unsubscribe AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , facets.email_channel.mail_event.mail.message_id message_id
            , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
            , facets.email_channel.mail_event.mail.from_address from_address
            , facets.email_channel.mail_event.mail.destination destination
            , facets.email_channel.mail_event.mail.common_headers.subject as subject
            , facets.email_channel.mail_event.click.ip_address as ip_address
            , facets.email_channel.mail_event.click.user_agent as user_agent
            , facets.email_channel.mail_event.click.link as link
            , facets.email_channel.mail_event.click.link_tags.unsubscribeLinkTag
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_email.unsubscribe')

  EventTableRejectNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Email Reject View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW email_rejected AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , facets.email_channel.mail_event.mail.message_id message_id
            , from_unixtime((facets.email_channel.mail_event.mail.message_send_timestamp / 1000)) message_send_timestamp
            , facets.email_channel.mail_event.mail.from_address from_address
            , facets.email_channel.mail_event.mail.destination destination
            , facets.email_channel.mail_event.mail.common_headers.subject as subject
            , facets.email_channel.mail_event.reject.reason as reject_reason
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_email.rejected')

  EventTableSMSBufferedNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the SMS Buffered View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW sms_buffered AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , attributes['sender_request_id'] as sender_request_id
            , attributes['destination_phone_number'] as destination_phone_number
            , attributes['record_status'] as record_status
            , attributes['iso_country_code'] as iso_country_code
            , attributes['number_of_message_parts'] as number_of_message_parts
            , attributes['message_id'] as message_id
            , attributes['message_type'] as message_type
            , metrics.price_in_millicents_usd as price_in_millicents_usd
            , CAST(JSON_PARSE(attributes['customer_context']) AS MAP(VARCHAR, VARCHAR)) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_SMS.BUFFERED')

  EventTableSMSSuccessNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the SMS Success View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW sms_success AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , attributes['sender_request_id'] as sender_request_id
            , attributes['destination_phone_number'] as destination_phone_number
            , attributes['record_status'] as record_status
            , attributes['iso_country_code'] as iso_country_code
            , attributes['number_of_message_parts'] as number_of_message_parts
            , attributes['message_id'] as message_id
            , attributes['message_type'] as message_type
            , attributes['origination_phone_number'] as origination_phone_number
            , metrics.price_in_millicents_usd as price_in_millicents_usd
            , CAST(JSON_PARSE(attributes['customer_context']) AS MAP(VARCHAR, VARCHAR)) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_SMS.SUCCESS')

  EventTableSMSFailureNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the SMS Failure View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW sms_failure AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , attributes['sender_request_id'] as sender_request_id
            , attributes['destination_phone_number'] as destination_phone_number
            , attributes['record_status'] as record_status
            , attributes['iso_country_code'] as iso_country_code
            , attributes['number_of_message_parts'] as number_of_message_parts
            , attributes['message_id'] as message_id
            , metrics.price_in_millicents_usd as price_in_millicents_usd
            , CAST(JSON_PARSE(attributes['customer_context']) AS MAP(VARCHAR, VARCHAR)) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_SMS.FAILURE')

  EventTableSMSOptOutNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the SMS Output View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW sms_optout AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , attributes['sender_request_id'] as sender_request_id
            , attributes['destination_phone_number'] as destination_phone_number
            , attributes['record_status'] as record_status
            , attributes['iso_country_code'] as iso_country_code
            , attributes['number_of_message_parts'] as number_of_message_parts
            , attributes['message_id'] as message_id
            , attributes['message_type'] as message_type
            , attributes['origination_phone_number'] as origination_phone_number
            , metrics.price_in_millicents_usd as price_in_millicents_usd
            , CAST(JSON_PARSE(attributes['customer_context']) AS MAP(VARCHAR, VARCHAR)) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_SMS.OPTOUT')

  EventTableCampaignSendNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Campaign Send View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW campaign_send AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['campaign_id'] pinpoint_campaign_id
            , attributes['treament_id'] pinpoint_treatment_id
            , awsaccountid aws_account_id
            , attributes as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_campaign.send')

  EventTableJourneySendNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Journey Send View"
      QueryString:
        !Sub
          |
            CREATE OR REPLACE VIEW journey_send AS
            SELECT
              from_unixtime((event_timestamp / 1000)) event_timestamp
            , from_unixtime((arrival_timestamp / 1000)) arrival_timestamp
            , application.app_id application_id
            , client.client_id endpoint_id
            , attributes['journey_run_id'] journey_run_id
            , attributes['journey_send_status'] journey_send_status
            , attributes['journey_id'] journey_id
            , attributes['journey_activity_id'] journey_activity_id
            , awsaccountid aws_account_id
            , MAP_CONCAT(COALESCE(client_context.custom, CAST(JSON '{}' AS MAP(varchar,varchar))),  attributes) as message_tags
            , ingest_timestamp
            FROM
              all_events
            WHERE (event_type = '_journey.send')

  ### Partitioner Lambda Helper
  AthenaPartitionLambda:
    Type: AWS::Lambda::Function
    Properties:
      Role: !GetAtt AthenaPartitionLambdaRole.Arn
      Timeout: 60
      Environment:
        Variables:
          LOG_LEVEL: "INFO"
          DATABASE_NAME: !Ref EventAthenaDatabaseName
          SOLUTION_ID: !FindInMap ["MetricsMap", "Send-Data", "ID"]
          SOLUTION_VERSION: !FindInMap ["MetricsMap", "Send-Data", "Version"]
          SEND_ANONYMOUS_DATA: !FindInMap ["MetricsMap", "Send-Data", "SendAnonymousData"]
          SOLUTION_UUID: !GetAtt GenerateUUID.UUID
      Handler: lambda_function.lambda_handler
      Runtime: !FindInMap ["LambdaRuntime", "Language", "Python"]
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCode", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCode", "General", "KeyPrefix"],  "athena-partition-lambda.zip"]]


  AthenaPartitionLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"

  AthenaPartitionLambdaRolePolicy:
    Type: AWS::IAM::Policy
    Properties:
      Roles:
        - !Ref AthenaPartitionLambdaRole
      PolicyName: "AthenaPartitionLambdaRolePolicy"
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Action:
              - "s3:GetBucketLocation"
              - "s3:GetObject"
              - "s3:ListBucket"
              - "s3:ListBucketMultipartUploads"
              - "s3:ListMultipartUploadParts"
              - "s3:AbortMultipartUpload"
              - "s3:CreateBucket"
              - "s3:PutObject"
            Resource:
              - !Sub arn:aws:s3:::${DUES3DataLakeName}
              - !Sub arn:aws:s3:::${DUES3DataLakeName}/*
          -
            Effect: "Allow"
            Action:
              - "athena:StartQueryExecution"
            Resource: !Sub "arn:aws:athena:${AWS::Region}:${AWS::AccountId}:workgroup/*"
          -
            Effect: "Allow"
            Action:
              - "glue:GetDatabase"
              - "glue:GetDatabases"
              - "glue:GetTable"
              - "glue:GetTables"
              - "glue:GetPartition"
              - "glue:GetPartitions"
              - "glue:CreateTable"
              - "glue:CreatePartition"
              - "glue:BatchCreatePartition"
            Resource:
              - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${EventAthenaDatabaseName}/*"
              - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${EventAthenaDatabaseName}"
              - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog"
          -
            Effect: "Allow"
            Action:
              - "logs:CreateLogGroup"
              - "logs:CreateLogStream"
              - "logs:PutLogEvents"
            Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"


  ### Deployment Helper
  SetupSampleFilesDUE:
    Type: Custom::LoadLambda
    Properties:
      ServiceToken: !GetAtt CustomResourceHelperDUE.Arn
      CustomResourceAction: SetupSampleFiles

  CustomResourceHelperDUE:
    Type: AWS::Lambda::Function
    Properties:
      Environment:
        Variables:
          LOG_LEVEL: "INFO"
          S3_DATA_BUCKET: !Ref DUES3DataLake
          EXISTING_CS: !Ref ConfigurationSetNames
          ALL_EVENT_TABLE: !Ref EventTableAllNamedQuery
          SEND_NQ: !Ref EventTableSendNamedQuery
          HARD_BOUNCE_NQ: !Ref EventTableHardBounceNamedQuery
          SOFT_BOUNCE_NQ: !Ref EventTableSoftBounceNamedQuery
          COMPLAINT_NQ: !Ref EventTableComplaintNamedQuery
          DELIVERY_NQ: !Ref EventTableDeliveryNamedQuery
          OPEN_NQ: !Ref EventTableOpenNamedQuery
          CLICK_NQ: !Ref EventTableClickNamedQuery
          UNSUB_NQ: !Ref EventTableUnsubNamedQuery
          REJECT_NQ: !Ref EventTableRejectNamedQuery
          SMS_BUFF_NQ: !Ref EventTableSMSBufferedNamedQuery
          SMS_SUCCESS_NQ: !Ref EventTableSMSSuccessNamedQuery
          SMS_FAILURE_NQ: !Ref EventTableSMSFailureNamedQuery
          SMS_OPTOUT_NQ: !Ref EventTableSMSOptOutNamedQuery
          CAMPAIGN_SEND_NQ: !Ref EventTableCampaignSendNamedQuery
          JOURNEY_SEND_NQ: !Ref EventTableJourneySendNamedQuery
          PINPOINT_PROJECT_ARN: !Sub
            - 'arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ProjectId}'
            - {ProjectId: !Ref PinpointProject}
      Description: Helps set up the solution.
      MemorySize: 256
      Role: !GetAtt CustomResourceHelperRoleDUE.Arn
      Timeout: 300
      Handler: lambda_function.lambda_handler
      Runtime: !FindInMap ["LambdaRuntime", "Language", "Python"]
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCode", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCode", "General", "KeyPrefix"],  "custom-resource-helper.zip"]]


  CustomResourceHelperRoleDUE:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"


  CustomResourceHelperPolicy:
      Type: AWS::IAM::Policy
      Properties:
        Roles:
          - !Ref CustomResourceHelperRoleDUE
        PolicyName: CustomResourceHelperPolicy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
            -
              Effect: Allow
              Action:
                - "s3:GetBucketLocation"
                - "s3:GetObject"
                - "s3:ListBucket"
                - "s3:ListBucketMultipartUploads"
                - "s3:ListMultipartUploadParts"
                - "s3:AbortMultipartUpload"
                - "s3:CreateBucket"
                - "s3:PutObject"
              Resource:
                - !Sub "arn:aws:s3:::${DUES3DataLakeName}"
                - !Sub "arn:aws:s3:::${DUES3DataLakeName}*"
            -
              Effect: "Allow"
              Action:
                - "athena:StartQueryExecution"
                - "athena:GetNamedQuery"
                - "athena:BatchGetNamedQuery"
                - "athena:GetQueryExecution"
              Resource: !Sub "arn:aws:athena:${AWS::Region}:${AWS::AccountId}:workgroup/*"
            -
              Effect: "Allow"
              Action:
                - "glue:GetDatabase"
                - "glue:GetDatabases"
                - "glue:GetTable"
                - "glue:GetTables"
                - "glue:GetPartition"
                - "glue:GetPartitions"
                - "glue:CreateTable"
              Resource:
                - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${EventAthenaDatabaseName}/*"
                - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${EventAthenaDatabaseName}"
                - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog"
            -
              Effect: "Allow"
              Action:
                - ses:CreateConfigurationSetEventDestination
              Resource: !Sub "arn:aws:ses:${AWS::Region}:${AWS::AccountId}:configuration-set/*"
            -
              Effect: "Allow"
              Action:
                - mobiletargeting:GetApp
              Resource: !Sub
                - 'arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ProjectId}'
                - {ProjectId: !Ref PinpointProject }
            -
              Effect: "Allow"
              Action:
                - "logs:CreateLogGroup"
                - "logs:CreateLogStream"
                - "logs:PutLogEvents"
              Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"

  DUES3DataLakeName:
    Type: Custom::BucketName
    Properties:
      ServiceToken: !GetAtt CustomBucketNameHelper.Arn
      CustomResourceAction: CreateBucket

  GenerateUUID:
    Type: Custom::LoadLambda
    Properties:
      ServiceToken: !GetAtt CustomBucketNameHelper.Arn
      CustomResourceAction: GenerateUUID

  # This must be a separate Lambda Helper to avoid circular dependencies
  CustomBucketNameHelper:
    Type: AWS::Lambda::Function
    Properties:
      Description: Helps create a unique bucket name
      Timeout: 30
      Role: !GetAtt CustomBucketNameHelperRole.Arn
      Environment:
        Variables:
          LOG_LEVEL: "INFO"
      Handler: lambda_function.lambda_handler
      Runtime: !FindInMap ["LambdaRuntime", "Language", "Python"]
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCode", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCode", "General", "KeyPrefix"],  "custom-bucket-name-helper.zip"]]


  CustomBucketNameHelperRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
            Condition: {}
      Path: /
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"


           
  DefaultVpcLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: PredictiveSegmentationCFGetDefaultVpcId
      Code:
        ZipFile: |
          import json
          import boto3
          import cfnresponse

          ec2 = boto3.client('ec2')

          def lambda_handler(event, context):              
              if 'RequestType' in event and event['RequestType'] == 'Create':
                  vpc_id = get_default_vpc_id()
                  subnets =  get_subnets_for_vpc(vpc_id)
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {'VpcId': vpc_id , "Subnets" : subnets}, '')
              else:
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {},'')

          def get_default_vpc_id():
              vpcs = ec2.describe_vpcs(Filters=[{'Name': 'is-default', 'Values': ['true']}])
              vpcs = vpcs['Vpcs']
              vpc_id = vpcs[0]['VpcId']
              return vpc_id


          def get_subnets_for_vpc(vpcId):
              response = ec2.describe_subnets(
                  Filters=[
                      {
                          'Name': 'vpc-id',
                          'Values': [vpcId]
                      }
                  ]
              )
              subnet_ids = []
              for subnet in response['Subnets']:
                  subnet_ids.append(subnet['SubnetId'])
              return subnet_ids 
      Description: Return default VPC ID and Subnets
      Handler: index.lambda_handler
      MemorySize: 512
      Role: !GetAtt DefaultVpcLambdaExecutionRole.Arn
      Runtime: python3.7
      Timeout: 900

  DefaultVpcLambdaExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - "sts:AssumeRole"
      Path: /
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess'
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'      

  DefaultVpcFinder:
    Type: Custom::ResourceForFindingDefaultVpc
    Properties:
      ServiceToken: !GetAtt DefaultVpcLambda.Arn



  #!# PS sections start
  DataS3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W51
            reason: Not public facing.
    Properties:
      PublicAccessBlockConfiguration:
        BlockPublicAcls: True
        BlockPublicPolicy: True
        IgnorePublicAcls: True
        RestrictPublicBuckets: True
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      LoggingConfiguration:
        DestinationBucketName: !Ref LogBucket
        LogFilePrefix: predictive-segmentation-data/

  DataS3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref DataS3Bucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: AllowSSLRequestsOnly
            Effect: Deny
            Principal: "*"
            Action: "s3:*"
            Resource:
              - !Sub "arn:aws:s3:::${DataS3Bucket}/*"
              - !Sub "arn:aws:s3:::${DataS3Bucket}"
            Condition:
              Bool:
                "aws:SecureTransport": "false"


  NotebookS3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W51
            reason: Not public facing.
    Properties:
      PublicAccessBlockConfiguration:
        BlockPublicAcls: True
        BlockPublicPolicy: True
        IgnorePublicAcls: True
        RestrictPublicBuckets: True
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      LoggingConfiguration:
        DestinationBucketName: !Ref LogBucket
        LogFilePrefix: notebook-data-bucket/

  NotebookS3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref NotebookS3Bucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
        - Sid: AllowSSLRequestsOnly
          Effect: Deny
          Principal: "*"
          Action: "s3:*"
          Resource:
            - !Sub "arn:aws:s3:::${NotebookS3Bucket}/*"
            - !Sub "arn:aws:s3:::${NotebookS3Bucket}"
          Condition:
            Bool:
              "aws:SecureTransport": "false"

  LogBucketPS:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W35
            reason: This is the log bucket.
    Properties:
      AccessControl: LogDeliveryWrite
      PublicAccessBlockConfiguration:
        BlockPublicAcls: True
        BlockPublicPolicy: True
        IgnorePublicAcls: True
        RestrictPublicBuckets: True
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
  LogBucketPolicyPS:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref LogBucketPS
      PolicyDocument:
        Version: 2012-10-17
        Statement:
        - Sid: AWSCloudTrailAclCheck
          Effect: Allow
          Principal:
            Service: cloudtrail.amazonaws.com
          Action: "s3:GetBucketAcl"
          Resource: !Sub arn:aws:s3:::${LogBucketPS}
        - Sid: AWSCloudTrailWrite
          Effect: Allow
          Principal:
            Service: cloudtrail.amazonaws.com
          Action: "s3:PutObject"
          Resource: !Sub arn:aws:s3:::${LogBucketPS}/AWSLogs/${AWS::AccountId}/*
          Condition:
            StringEquals:
              "s3:x-amz-acl": "bucket-owner-full-control"
        - Sid: LogBucketAllowSSLRequestsOnly
          Effect: Deny
          Principal: "*"
          Action: "s3:*"
          Resource:
            - !Sub "arn:aws:s3:::${LogBucketPS}/*"
            - !Sub "arn:aws:s3:::${LogBucketPS}"
          Condition:
            Bool:
              "aws:SecureTransport": "false"

  S3Endpoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      ServiceName: !Sub com.amazonaws.${AWS::Region}.s3
      VpcId: !GetAtt DefaultVpcFinder.VpcId
      PolicyDocument: !Sub
        |
          {
            "Version":"2012-10-17",
            "Statement":[
              {
                "Effect":"Allow",
                "Principal": "*",
                "Action": "*",
                "Resource":[
                  "arn:aws:s3:::${NotebookS3Bucket}/*",
                  "arn:aws:s3:::${NotebookS3Bucket}",
                  "arn:aws:s3:::churnv2-${AWS::Region}/*",
                  "arn:aws:s3:::churnv2-${AWS::Region}"
                ]
              }
            ]
          }

  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Metadata:
      cfn_nag:
        rules_to_suppress:
          -
            id: "W5"
            reason: "Allow notebook users to access the internet from the notebook. Needed to get demo data"
          -
            id: "W36"
            reason: "Security Group has a description that includes description of egress rule"
    Properties:
      GroupDescription: "Notebook instance security group. By default allows connection to the internet"
      VpcId: !GetAtt DefaultVpcFinder.VpcId
      SecurityGroupEgress:
         -
          IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: "0.0.0.0/0"

  NotebookInstanceVolumeEncryptionKey:
    Type: AWS::KMS::Key
    Properties:
      Description: "KMS Key for encrypting sagemaker notebook instance volume"
      Enabled: true
      EnableKeyRotation: true
      PendingWindowInDays: 7
      KeyPolicy:
        Version: 2012-10-17
        Id: "default-key-policy"
        Statement:
          -
            Sid: "Enable IAM User Permissions"
            Effect: Allow
            Principal:
              AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
            Action: "kms:*"
            Resource: "*"

  BasicNotebookInstance:
    Type: 'AWS::SageMaker::NotebookInstance'
    Properties:
      InstanceType: ml.t2.medium
      NotebookInstanceName: PredictiveChurnNotebookInstance
      SubnetId: !Select [ "0", !GetAtt DefaultVpcFinder.Subnets ]
      SecurityGroupIds:
        - !Ref SecurityGroup
      KmsKeyId: !Ref NotebookInstanceVolumeEncryptionKey
      RoleArn: !GetAtt NotebookInstanceExecutionRole.Arn
      LifecycleConfigName: !GetAtt
        - BasicNotebookInstanceLifecycleConfig
        - NotebookInstanceLifecycleConfigName
  BasicNotebookInstanceLifecycleConfig:
    Type: 'AWS::SageMaker::NotebookInstanceLifecycleConfig'
    Properties:
      OnStart:
        - Content: !Base64
            'Fn::Join':
              - ;
              - - cd /home/ec2-user/SageMaker
                - !Sub 'aws s3 cp s3://solutions-${AWS::Region}/predictive-segmentation-using-amazon-pinpoint-and-amazon-sagemaker/v1.1.0/xgboost_customer_churn.ipynb .'
                - !Sub 'aws s3 cp s3://solutions-${AWS::Region}/predictive-segmentation-using-amazon-pinpoint-and-amazon-sagemaker/v1.1.0/ChurnSampleData.csv .'
                - !Join
                  - ''
                  - - sed -i 's/S3BucketName/
                    - !Ref NotebookS3Bucket
                    - /g' xgboost_customer_churn.ipynb
                - sed -i 's/S3Prefix/pred-maintenance-artifacts/g' xgboost_customer_churn.ipynb
                - !Join
                  - ''
                  - - sed -i 's/deployed-xgboost-customer-churn/
                    - !FindInMap ["Variables", "General", "SageMakerModelName"]
                    - /g' xgboost_customer_churn.ipynb
                - !Join
                  - ''
                  - - sed -i 's/ml.m4.xlarge/
                    - !Ref SageMakerModelTrainInstanceType
                    - /g' xgboost_customer_churn.ipynb


  NotebookInstanceExecutionRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - sagemaker.amazonaws.com
            Action:
              - 'sts:AssumeRole'

  NotebookInstanceIAMPolicy:
    Type: 'AWS::IAM::Policy'
    Properties:
      PolicyName: sm-notebook-instance-policy
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - 's3:CreateBucket'
              - 's3:GetBucketLocation'
              - 's3:ListBucket'
              - 's3:GetObject'
              - 's3:PutObject'
              - 's3:DeleteObject'
            Resource:
              - "arn:aws:s3:::solutions"
              - "arn:aws:s3:::solutions*"
              - !GetAtt NotebookS3Bucket.Arn
              - !Join
                    - ""
                    - - !GetAtt NotebookS3Bucket.Arn
                      - "*"
              - !Sub "arn:aws:s3:::${DataS3Bucket}*"
              - !Sub "arn:aws:s3:::${DataS3Bucket}"
          - Effect: Allow
            Action:
              - 'sagemaker:CreateTrainingJob'
              - 'sagemaker:DescribeTrainingJob'
              - 'sagemaker:CreateModel'
              - 'sagemaker:DescribeModel'
              - 'sagemaker:DeleteModel'
              - 'sagemaker:DescribeTransformJob'
              - 'sagemaker:CreateTransformJob'
              - 'sagemaker:DescribeNotebookInstance'
            Resource:
              - !Join
                - ''
                - - 'arn:aws:sagemaker:'
                  - !Ref 'AWS::Region'
                  - ':'
                  - !Ref 'AWS::AccountId'
                  - ':*'
          - Effect: Allow
            Action:
              - 'ecr:GetAuthorizationToken'
              - 'ecr:GetDownloadUrlForLayer'
              - 'ecr:BatchGetImage'
              - 'ecr:BatchCheckLayerAvailability'
            Resource:
              - !Join
                - ''
                - - 'arn:aws:ecr:'
                  - !Ref 'AWS::Region'
                  - ':'
                  - !Ref 'AWS::AccountId'
                  - ':repository/*'
          - Effect: Allow
            Action:
              - 'cloudwatch:PutMetricData'
              - 'cloudwatch:GetMetricData'
              - 'cloudwatch:GetMetricStatistics'
              - 'cloudwatch:ListMetrics'
            Resource:
              - !Join
                - ''
                - - 'arn:aws:cloudwatch:'
                  - !Ref 'AWS::Region'
                  - ':'
                  - !Ref 'AWS::AccountId'
                  - ':*'
          - Effect: Allow
            Action:
              - 'logs:CreateLogGroup'
              - 'logs:CreateLogStream'
              - 'logs:DescribeLogStreams'
              - 'logs:GetLogEvents'
              - 'logs:PutLogEvents'
            Resource: !Join
              - ''
              - - 'arn:aws:logs:'
                - !Ref 'AWS::Region'
                - ':'
                - !Ref 'AWS::AccountId'
                - ':log-group:/aws/sagemaker/*'
          - Effect: Allow
            Action:
              - 'iam:PassRole'
            Resource:
              - !GetAtt
                - NotebookInstanceExecutionRole
                - Arn
            Condition:
              StringEquals:
                'iam:PassedToService': sagemaker.amazonaws.com
          - Effect: Allow
            Action:
              - 'iam:GetRole'
            Resource:
              - !GetAtt
                - NotebookInstanceExecutionRole
                - Arn
      Roles:
        - !Ref NotebookInstanceExecutionRole

           
  AugmentEndpointNamedQuery:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Query to select customers and churn features for SageMaker consumption."
      QueryString: |
            WITH delivered AS (
              SELECT MAX(a.event_timestamp) max_time, MAX(e.address) address
              FROM endpoint_export e
              INNER JOIN email_delivered a ON e.id = a.endpoint_id
              WHERE a.ingest_timestamp > date_add('month', -12, date('2019-10-25'))
              GROUP BY e.id
             ),
            engaged AS (
              SELECT MAX(event_timestamp) max_time, MAX(e.address) address
              FROM endpoint_export e
              INNER JOIN email_open a ON e.id = a.endpoint_id
              WHERE a.ingest_timestamp > date_add('month', -12, date('2019-10-25'))
              GROUP BY e.id
              UNION ALL
              SELECT MAX(event_timestamp) max_time, MAX(e.address) address
              FROM endpoint_export e
              INNER JOIN email_click a ON e.id = a.endpoint_id
              WHERE a.ingest_timestamp > date_add('month', -12, date('2019-10-25'))
              GROUP BY e.id
              )

            SELECT
              a.id,
              MAX(a.address) AS EmailAddress,
              MAX(a.attributes['accountlength'][1]),
              MAX(a.attributes['planoptiona'][1]),
              MAX(a.attributes['planoptionb'][1]),
              MAX(a.attributes['planoptionc'][1]),
              MAX(a.attributes['usageweekdays'][1]),
              MAX(a.attributes['usageweekends'][1]),
              MAX(a.attributes['sharedwithfriend'][1]),
              MAX(CASE WHEN delivered.max_time < date_add('month', -6, date('2019-10-25'))  THEN 0
                  WHEN delivered.max_time < date_add('month', -1, date('2019-10-25')) THEN 1
                  ELSE 2 END),
              MAX(CASE WHEN engaged.max_time < date_add('month', -6, date('2019-10-25')) THEN 0
                  WHEN engaged.max_time < date_add('month', -1, date('2019-10-25')) THEN 1
                  ELSE 2 END)

            FROM endpoint_export a
            LEFT JOIN delivered ON a.address = delivered.address
            LEFT JOIN engaged ON a.address = engaged.address
            WHERE a.channeltype = 'EMAIL' AND a.endpointstatus = 'ACTIVE'
            GROUP BY a.id

  AthenaCreateTableEndpointExportsNamedQuery:
    Type: AWS::Athena::NamedQuery
    DeletionPolicy: Delete
    Properties:
      Database: !Ref PinpointEventDatabase
      Description: "Create the Endpoint Exports table from S3."
      QueryString:
        !Sub
          |
            CREATE EXTERNAL TABLE IF NOT EXISTS `${PinpointEventDatabase}`.endpoint_export (
              id string,
              channeltype string,
              address string,
              endpointstatus string,
              optout string,
              effectivedate string,
              attributes map<string,array<string>>,
              metrics map<string,array<string>>,
              user struct<userid:string, userattributes:map<string,array<string>>>
            )
            ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
            WITH SERDEPROPERTIES (
              'serialization.format' = '1'
            ) LOCATION 's3://${DataS3Bucket}/endpoint_exports/'
            TBLPROPERTIES ('has_encrypted_data'='false');



  ExportPinpointEndpointsLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt ExportPinpointEndpointsLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          PINPOINT_APPLICATION_ID: !Ref PinpointProject
          S3_BUCKET: !Ref DataS3Bucket
          ROLE_ARN: !GetAtt PinpointExportRole.Arn
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "02-export-pinpoint-endpoints-lambda.zip"]]


  ExportStatusLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt ExportStatusLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          PINPOINT_APPLICATION_ID: !Ref PinpointProject
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "03-export-status-lambda.zip"]]


  QueryAugmentStartLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt QueryAugmentStartLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          S3_BUCKET: !Ref DataS3Bucket
          NAMED_QUERY: !Ref AugmentEndpointNamedQuery
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "04-query-augment-start-lambda.zip"]]


  QueryStatusLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt QueryStatusLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "05-query-status-lambda.zip"]]


  RemoveHeaderFromQueryCSV:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt RemoveHeaderFromQueryCSVRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          S3_BUCKET: !Ref DataS3Bucket
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "06-remove-header-from-query-lambda.zip"]]



  SagemakerBatchTransformLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt SagemakerBatchTransformLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          MODEL_NAME: !FindInMap ["Variables", "General", "SageMakerModelName"]
          S3_BUCKET: !Ref DataS3Bucket
          TRANSFORM_INSTANCE: !Ref SageMakerTransformInstanceType
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "07-sagemaker-batch-transform-lambda.zip"]]




  BatchTransformStatusLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt BatchTransformStatusLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "08-batch-transform-status-lambda.zip"]]


  AddHeaderRowAndFilterLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt AddHeaderRowAndFilterLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          S3_BUCKET: !Ref DataS3Bucket
          METRIC_NAME: !FindInMap ["Variables", "General", "MetricName"]
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "09-add-header-row-filter-lambda.zip"]]



  ImportSegmentLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt ImportSegmentLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          S3_BUCKET: !Ref DataS3Bucket
          APPLICATION_ID: !Ref PinpointProject
          ROLE_ARN: !GetAtt PinpointImportRole.Arn
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "10-import-segment-lambda.zip"]]


  ImportSegmentStatusLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt ImportSegmentStatusLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          APPLICATION_ID: !Ref PinpointProject
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "11-import-segment-status-lambda.zip"]]


  ImportSegmentSuccessLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt ImportSegmentSuccessLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          APPLICATION_ID: !Ref PinpointProject
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "12-import-segment-success-lambda.zip"]]


  CleanupLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt CleanupLambdaRole.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 60
      Environment:
        Variables:
          S3_BUCKET: !Ref DataS3Bucket
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "01-cleanup-lambda.zip"]]



  DailyChurnListStateMachine:
    Type: AWS::StepFunctions::StateMachine
    DependsOn: CustomResourceHelperPS
    Properties:
      RoleArn: !GetAtt DailyChurnListStateMachineRole.Arn
      DefinitionString:
        !Sub
          - |-
            {
              "StartAt": "CleanStart",
              "States": {
                "CleanStart": {
                  "Type": "Task",
                  "Resource": "${CleanupArn}",
                  "Next": "ExportPinpointEndpoints"
                },
                "ExportPinpointEndpoints": {
                  "Type": "Task",
                  "Resource": "${ExportPinpointEndpointsArn}",
                  "Next": "ExportWait"
                },
                "ExportWait": {
                  "Type": "Wait",
                  "Seconds": 30,
                  "Next": "ExportStatus"
                },
                "ExportStatus": {
                  "Type": "Task",
                  "Resource": "${ExportStatusArn}",
                  "Next": "IsExportFinished"
                },
                "IsExportFinished": {
                  "Type": "Choice",
                  "Default": "ExportWait",
                  "Choices": [
                    {
                      "Variable": "$.ExportJobStatus",
                      "StringEquals": "FAILED",
                      "Next": "ExportFailed"
                    },
                    {
                      "Variable": "$.ExportJobStatus",
                      "StringEquals": "COMPLETED",
                      "Next": "QueryAugmentStart"
                    }
                  ]
                },
                "ExportFailed": {
                  "Type": "Fail",
                  "Cause": "Pinpoint Export failed",
                  "Error": "Pinpoint Export failed"
                },
                "QueryAugmentStart": {
                  "Type": "Task",
                  "Resource": "${QueryAugmentStartArn}",
                  "Next": "QueryWait"
                },
                "QueryWait" : {
                  "Type": "Wait",
                  "Seconds": 5,
                  "Next": "QueryStatus"
                },
                "QueryStatus": {
                  "Type": "Task",
                  "Resource": "${QueryStatusArn}",
                  "Next": "IsQueryFinished"
                },
                "IsQueryFinished":{
                  "Type": "Choice",
                  "Default": "QueryWait",
                  "Choices": [{
                      "Variable": "$.Status",
                      "StringEquals": "FAILED",
                      "Next": "QueryFailed"
                  },{
                      "Variable": "$.Status",
                      "StringEquals": "SUCCEEDED",
                      "Next": "RemoveHeaderFromQueryCSV"
                  }]
                },
                "QueryFailed": {
                  "Type": "Fail",
                  "Cause": "Athena Query failed",
                  "Error": "Athena Query failed"
                },
                "RemoveHeaderFromQueryCSV": {
                  "Type": "Task",
                  "Resource": "${RemoveHeaderFromQueryCSVArn}",
                  "Next": "SagemakerBatchTransform"
                },
                "SagemakerBatchTransform": {
                  "Type": "Task",
                  "Resource": "${SagemakerBatchTransformArn}",
                  "Next": "BatchTransformWait"
                },
                "BatchTransformWait": {
                  "Type": "Wait",
                  "Seconds": 30,
                  "Next": "BatchTransformStatus"
                },
                "BatchTransformStatus": {
                  "Type": "Task",
                  "Resource": "${BatchTransformStatusArn}",
                  "Next": "IsBatchTransformFinished"
                },
                "IsBatchTransformFinished": {
                  "Type": "Choice",
                  "Default": "BatchTransformWait",
                  "Choices": [
                    {
                      "Variable": "$.TransformJobStatus",
                      "StringEquals": "Failed",
                      "Next": "BatchTransformFailed"
                    },
                    {
                      "Variable": "$.TransformJobStatus",
                      "StringEquals": "Completed",
                      "Next": "AddHeaderRowAndFilter"
                    }
                  ]
                },
                "BatchTransformFailed": {
                  "Type": "Fail",
                  "Cause": "SageMaker BatchTransform failed",
                  "Error": "SageMaker BatchTransform failed"
                },
                "AddHeaderRowAndFilter": {
                  "Type": "Task",
                  "Resource": "${AddHeaderRowAndFilterLambdaArn}",
                  "Next": "AreRowsToImport"
                },
                "AreRowsToImport": {
                  "Type": "Choice",
                  "Default": "ImportLikelyChurnSegment",
                  "Choices": [
                    {
                      "Variable": "$.RowCount",
                      "NumericEquals": 0,
                      "Next": "NothingToImport"
                    }
                  ]
                },
                "NothingToImport" : {
                  "Type": "Pass",
                  "End": true
                },
                "ImportLikelyChurnSegment": {
                  "Type": "Task",
                  "Resource": "${ImportSegmentArn}",
                  "Next": "ImportSegmentWait"
                },
                "ImportSegmentWait": {
                  "Type": "Wait",
                  "Seconds": 20,
                  "Next": "ImportSegmentStatus"
                },
                "ImportSegmentStatus": {
                  "Type": "Task",
                  "Resource": "${ImportSegmentStatusArn}",
                  "Next": "IsImportSegmentFinished"
                },
                "IsImportSegmentFinished": {
                  "Type": "Choice",
                  "Default": "ImportSegmentWait",
                  "Choices": [
                    {
                      "Variable": "$.Status",
                      "StringEquals": "FAILED",
                      "Next": "ImportSegmentFailed"
                    },
                    {
                      "Variable": "$.Status",
                      "StringEquals": "COMPLETED",
                      "Next": "ImportSegmentSuccess"
                    }
                  ]
                },
                "ImportSegmentSuccess": {
                  "Type": "Task",
                  "Resource": "${ImportSegmentSuccessArn}",
                  "End": true
                },
                "ImportSegmentFailed": {
                  "Type": "Fail",
                  "Cause": "Pinpoint Import Segment failed",
                  "Error": "Pinpoint Import Segment failed"
                }
              }
            }
          - {ExportPinpointEndpointsArn: !GetAtt ExportPinpointEndpointsLambda.Arn, ExportStatusArn: !GetAtt ExportStatusLambda.Arn, QueryAugmentStartArn: !GetAtt QueryAugmentStartLambda.Arn, QueryStatusArn: !GetAtt QueryStatusLambda.Arn, RemoveHeaderFromQueryCSVArn: !GetAtt RemoveHeaderFromQueryCSV.Arn, SagemakerBatchTransformArn: !GetAtt SagemakerBatchTransformLambda.Arn, BatchTransformStatusArn: !GetAtt BatchTransformStatusLambda.Arn, AddHeaderRowAndFilterLambdaArn: !GetAtt AddHeaderRowAndFilterLambda.Arn, ImportSegmentArn: !GetAtt ImportSegmentLambda.Arn, ImportSegmentStatusArn: !GetAtt ImportSegmentStatusLambda.Arn, ImportSegmentSuccessArn: !GetAtt ImportSegmentSuccessLambda.Arn, CleanupArn: !GetAtt CleanupLambda.Arn}

  DailyChurnListCloudWatchEvent:
    Type: AWS::Events::Rule
    Properties:
      Description: "Run the DailyChurnListStateMachine Daily"
      ScheduleExpression: "cron(0 2 * * ? *)"
      State: "ENABLED"
      RoleArn: !GetAtt DailyChurnListCloudWatchEventRole.Arn
      Targets:
        -
          Arn: !Ref DailyChurnListStateMachine
          Id: "DailyChurnListStateMachine"
          RoleArn: !GetAtt DailyChurnListCloudWatchEventRole.Arn


  ExportPinpointEndpointsLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action: "iam:PassRole"
                Resource:
                  - !GetAtt PinpointExportRole.Arn
              -
                Effect: "Allow"
                Action:
                  - "mobiletargeting:CreateExportJob"
                Resource:
                  - !Sub 
                    - "arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ApplicationId}/jobs/export"
                    - {ApplicationId: !Ref PinpointProject}
                  - !Sub 
                    - "arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ApplicationId}"
                    - {ApplicationId: !Ref PinpointProject}

  ExportStatusLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "mobiletargeting:GetExportJob"
                Resource:
                  - !Sub 
                    - "arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ApplicationId}/jobs/export/*"
                    - {ApplicationId: !Ref PinpointProject}

  QueryAugmentStartLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "s3:GetBucketLocation"
                  - "s3:GetObject"
                  - "s3:ListBucket"
                  - "s3:ListBucketMultipartUploads"
                  - "s3:ListMultipartUploadParts"
                  - "s3:AbortMultipartUpload"
                  - "s3:CreateBucket"
                  - "s3:PutObject"
                Resource:
                  - !Sub "arn:aws:s3:::${DataS3Bucket}/*"
                  - !Sub "arn:aws:s3:::${DataS3Bucket}"
                  - !Sub "arn:aws:s3:::${DUES3DataLakeName}/*"
                  - !Sub "arn:aws:s3:::${DUES3DataLakeName}"
              -
                Effect: "Allow"
                Action:
                  - "athena:StartQueryExecution"
                  - "athena:GetNamedQuery"
                Resource: !Sub "arn:aws:athena:${AWS::Region}:${AWS::AccountId}:workgroup/*"
              -
                Effect: "Allow"
                Action:
                  - "glue:GetDatabase"
                  - "glue:GetDatabases"
                  - "glue:GetTable"
                  - "glue:GetTables"
                  - "glue:GetPartition"
                  - "glue:GetPartitions"
                Resource:
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${PinpointEventDatabase}/*"
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${PinpointEventDatabase}"
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog"

  QueryStatusLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "athena:GetQueryExecution"
                Resource: !Sub "arn:aws:athena:${AWS::Region}:${AWS::AccountId}:workgroup/*"

  RemoveHeaderFromQueryCSVRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "s3:GetObject"
                  - "s3:PutObject"
                Resource:
                  - !Sub "arn:aws:s3:::${DataS3Bucket}/*"

  SagemakerBatchTransformLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: Allow
                Action:
                  - 'sagemaker:CreateTransformJob'
                Resource:
                  - 'arn:aws:sagemaker:*:*:transform-job/*'

  BatchTransformStatusLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: Allow
                Action:
                  - 'sagemaker:DescribeTransformJob'
                Resource:
                  - 'arn:aws:sagemaker:*:*:transform-job/*'

  AddHeaderRowAndFilterLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "s3:GetObject"
                  - "s3:PutObject"
                Resource:
                  - !Sub "arn:aws:s3:::${DataS3Bucket}/*"

  ImportSegmentLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "mobiletargeting:GetSegmentVersion"
                  - "mobiletargeting:GetSegment"
                  - "mobiletargeting:GetSegments"
                  - "mobiletargeting:GetSegmentVersions"
                  - "mobiletargeting:CreateImportJob"
                Resource:
                  - !Sub
                    - "arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ApplicationId}*"
                    - {ApplicationId: !Ref PinpointProject}
                  - !Sub
                    - "arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ApplicationId}"
                    - {ApplicationId: !Ref PinpointProject}                  
              -
                Effect: "Allow"
                Action: "iam:PassRole"
                Resource:
                - !GetAtt PinpointImportRole.Arn

  ImportSegmentStatusLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "mobiletargeting:GetImportJob"
                Resource:
                  - !Sub 
                    - "arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ApplicationId}/jobs/import/*"
                    - {ApplicationId: !Ref PinpointProject}                  

  ImportSegmentSuccessLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "mobiletargeting:GetSegment"
                  - "mobiletargeting:TagResource"
                Resource:
                  - !Sub 
                    - "arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ApplicationId}*"
                    - {ApplicationId: !Ref PinpointProject} 

  CleanupLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "s3:ListBucket"
                  - "s3:DeleteObject"
                Resource:
                  - !Sub "arn:aws:s3:::${DataS3Bucket}/*"
                  - !Sub "arn:aws:s3:::${DataS3Bucket}"


  DailyChurnListStateMachineRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W76
            reason: Complex Role that is used for StateMachine to invoke many other lambdas
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "states.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action: "lambda:InvokeFunction"
                Resource:
                  - !GetAtt ExportPinpointEndpointsLambda.Arn
                  - !GetAtt ExportStatusLambda.Arn
                  - !GetAtt QueryAugmentStartLambda.Arn
                  - !GetAtt QueryStatusLambda.Arn
                  - !GetAtt RemoveHeaderFromQueryCSV.Arn
                  - !GetAtt SagemakerBatchTransformLambda.Arn
                  - !GetAtt BatchTransformStatusLambda.Arn
                  - !GetAtt AddHeaderRowAndFilterLambda.Arn
                  - !GetAtt ImportSegmentLambda.Arn
                  - !GetAtt ImportSegmentStatusLambda.Arn
                  - !GetAtt ImportSegmentSuccessLambda.Arn
                  - !GetAtt CleanupLambda.Arn

  PinpointImportRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - pinpoint.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "s3:GetObject"
                  - "s3:ListBucket"
                Resource:
                  - !Sub "arn:aws:s3:::${DataS3Bucket}*"
                  - !Sub "arn:aws:s3:::${DataS3Bucket}"

  PinpointExportRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - pinpoint.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "s3:PutObject"
                  - "s3:GetObjectAcl"
                  - "s3:GetObject"
                  - "s3:DeleteObjectVersion"
                  - "s3:GetObjectTagging"
                  - "s3:DeleteObject"
                  - "s3:GetObjectVersion"
                Resource:
                  - !Sub "arn:aws:s3:::${DataS3Bucket}*"
                  - !Sub "arn:aws:s3:::${DataS3Bucket}"
                  - !Sub "arn:aws:s3:::${DataS3Bucket}/"
                  - !Sub "arn:aws:s3:::${DataS3Bucket}/*"
              -
                Effect: "Allow"
                Action:
                  - "s3:ListAllMyBuckets"
                  - "s3:GetBucketLocation"
                Resource:
                  - !Sub "arn:aws:s3:::*"

  DailyChurnListCloudWatchEventRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - "events.amazonaws.com"
            Action:
              - 'sts:AssumeRole'
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action: "states:StartExecution"
                Resource: !Ref DailyChurnListStateMachine

  #Deployment Helper Function
  SetupSampleFilesPS:
    Type: Custom::LoadLambda
    DependsOn: OptionalPolicyForSampleEvents
    Properties:
      ServiceToken: !GetAtt CustomResourceHelperPS.Arn
      CustomResourceAction: SetupSampleFiles

  CustomResourceHelperPS:
    Type: AWS::Lambda::Function
    Properties:
      Environment:
        Variables:
          SOLUTION_BUCKET: !Join
            - "-"
            - - !FindInMap ["SourceCodePS", "General", "S3Bucket"]
              - !Ref AWS::Region
          SOLUTION_S3KEYPREFIX: !FindInMap ["SourceCodePS", "General", "KeyPrefix"]
          S3_DATA_BUCKET: !Ref DataS3Bucket
          METRIC_NAME: !FindInMap ["Variables", "General", "MetricName"]
          CHURN_PREDICTION_THRESHOLD: !FindInMap ["Variables", "General", "ChurnPredictionThreashold"]
          SEGMENT_NAME: !FindInMap ["Variables", "General", "SegmentName"]
          EXPORT_NAMED_QUERY: !Ref AthenaCreateTableEndpointExportsNamedQuery
          APPLICATION_ID: !Ref PinpointProject
          DUE_DB_S3_BUCKET: !Ref DUES3DataLakeName
          LOAD_SAMPLE_EVENTS: !Ref DeploySampleEvents
      Description: Helps set up the Predictive Segmentation using Amazon Pinpoint and Amazon SageMaker solution.
      Handler: index.handler
      MemorySize: 256
      Role: !GetAtt CustomResourceHelperRolePS.Arn
      Runtime: !FindInMap ["SourceCodePS", "Runtime", "Nodejs"]
      Timeout: 300
      Code:
        S3Bucket: !Join ["-", [!FindInMap ["SourceCodePS", "General", "S3Bucket"], Ref: "AWS::Region" ]]
        S3Key: !Join ["/", [!FindInMap ["SourceCodePS", "General", "KeyPrefix"],  "custom-resource-helper.zip"]]


  CustomResourceHelperRolePS:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              -
                Effect: Allow
                Action:
                  - "s3:GetObject"
                Resource:
                  - !Join
                    - ""
                    - - "arn:aws:s3:::"
                      - !FindInMap ["SourceCodePS", "General", "S3Bucket"]
                      - "-"
                      - !Ref AWS::Region
                  - !Join
                    - ""
                    - - "arn:aws:s3:::"
                      - !FindInMap ["SourceCodePS", "General", "S3Bucket"]
                      - "-"
                      - !Ref AWS::Region
                      - "/*"
              -
                Effect: Allow
                Action:
                  - "s3:GetBucketLocation"
                  - "s3:GetObject"
                  - "s3:ListBucket"
                  - "s3:ListBucketMultipartUploads"
                  - "s3:ListMultipartUploadParts"
                  - "s3:AbortMultipartUpload"
                  - "s3:PutObject"
                Resource:
                  - !Sub "arn:aws:s3:::${DataS3Bucket}"
                  - !Sub "arn:aws:s3:::${DataS3Bucket}/*"
              -
                Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutDestination
                  - logs:PutLogEvents
                Resource:
                  - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
              -
                Effect: "Allow"
                Action:
                  - "athena:StartQueryExecution"
                  - "athena:GetNamedQuery"
                  - "athena:BatchGetNamedQuery"
                  - "athena:GetQueryExecution"
                Resource: !Sub "arn:aws:athena:${AWS::Region}:${AWS::AccountId}:workgroup/*"
              -
                Effect: "Allow"
                Action:
                  - "glue:GetDatabase"
                  - "glue:GetDatabases"
                  - "glue:GetTable"
                  - "glue:GetTables"
                  - "glue:GetPartition"
                  - "glue:GetPartitions"
                  - "glue:CreateTable"
                Resource:
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${PinpointEventDatabase}/*"
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${PinpointEventDatabase}"
                  - !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog"
              -
                Effect: "Allow"
                Action:
                  - "mobiletargeting:CreateSegment"
                Resource:
                  - !Sub 
                    - "arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ApplicationId}"
                    - {ApplicationId: !Ref PinpointProject}

  OptionalPolicyForSampleEvents:
    Type: AWS::IAM::Policy
    Condition: LoadSampleEvents
    Properties:
      PolicyName: PredSegmentDeploySampleEvents
      Roles:
        - !Ref CustomResourceHelperRolePS
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          -
            Effect: Allow
            Action:
              - "s3:GetObject"
              - "s3:PutObject"
            Resource:
              - !Sub "arn:aws:s3:::${DUES3DataLakeName}/*"



Outputs:
  BasicNotebookInstanceName:
    Description: Amazon SageMaker Notebook Instance Name
    Value: !GetAtt BasicNotebookInstance.NotebookInstanceName   

  DUES3DataLakeName:
    Description: S3 Bucket Name where the S3 Data Lake and Events are stored
    Value: !Ref DUES3DataLakeName
  PinpointProjectId:
    Description: Amazon Pinpoint Project ID that was configured by the solution
    Value: !Ref PinpointProject
  PinpointProjectArn:
    Description: Full AWS Arn of the Amazon Pinpoint Project that was configured by the solution
    Value: !Sub
      - 'arn:aws:mobiletargeting:${AWS::Region}:${AWS::AccountId}:apps/${ProjectId}'
      - {ProjectId: !Ref PinpointProject }
  PinpointEventStreamFirehoseName:
    Description: Name of the Amazon Kinesis Firehose used in the Amazon Pinpoint Event Stream Configuration
    Value: !Ref PinpointEventFirehose
  PinpointEventStreamFirehoseRoleName:
    Description: IAM role that Amazon Pinpoint Event Stream uses to write to Amazon Kinesis Firehose
    Value: !Ref PinpointKinesisStreamRole